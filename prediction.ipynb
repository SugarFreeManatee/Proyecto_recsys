{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafa/.pyenv/versions/3.10.12/envs/recsys/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"word2vec128.wordvectors\", mmap='r')\n",
    "df_playlists_train = pd.read_csv('data/train_playlists.csv', sep='\\t')\n",
    "df_playlists_train['track_uris'] = df_playlists_train['track_uris'].apply(lambda x: x.strip('[]').replace(\"'\", \"\").split(', '))\n",
    "df_playlists_val = pd.read_csv('data/validation_playlists_sample.csv', sep='\\t').dropna().reset_index(drop=True)\n",
    "df_playlists_val['track_uris'] = df_playlists_val['track_uris'].apply(lambda x: x.strip('[]').replace(\"'\", \"\").split(', '))\n",
    "\n",
    "wv.sort_by_descending_frequency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaylistDataset(Dataset):\n",
    "    def __init__(self, playlists, wv):\n",
    "        self.playlists = playlists\n",
    "        self.wv = wv\n",
    "    def __len__(self):\n",
    "        return len(self.playlists)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        playlist = self.playlists[idx]\n",
    "        playlist = [self.wv.key_to_index[word] for word in playlist]\n",
    "        src = playlist[:-1]  # All except the last token\n",
    "        tgt = playlist[1:]   # All except the first token\n",
    "        return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_lens = [len(src) for src in src_batch]\n",
    "    max_src_len = max(src_lens)\n",
    "\n",
    "    # Pad sequences\n",
    "    padded_src_batch = torch.zeros((len(src_batch), max_src_len), dtype=torch.long)\n",
    "    padded_tgt_batch = torch.zeros((len(tgt_batch), max_src_len), dtype=torch.long)\n",
    "    src_attention_masks = torch.zeros((len(src_batch), max_src_len), dtype=torch.bool)\n",
    "\n",
    "    for i, (src, tgt) in enumerate(zip(src_batch, tgt_batch)):\n",
    "        padded_src_batch[i, :len(src)] = src\n",
    "        padded_tgt_batch[i, :len(tgt)] = tgt\n",
    "        src_attention_masks[i, :len(src)] = 1\n",
    "\n",
    "    return padded_src_batch, padded_tgt_batch, src_attention_masks\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, playlists, wv):\n",
    "        self.playlists = playlists\n",
    "        self.wv = wv\n",
    "    def __len__(self):\n",
    "        return len(self.playlists)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        playlist = self.playlists.iloc[idx]\n",
    "        src = [self.wv.key_to_index[word] for word in playlist[\"x\"]]\n",
    "        tgt = [self.wv.key_to_index[word] for word in playlist[\"y\"]]\n",
    "        return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout, cutoffs, embedding_model = None, wv = None, cat = True):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.adaptive_softmax = nn.AdaptiveLogSoftmaxWithLoss(\n",
    "            hidden_dim, vocab_size, cutoffs=cutoffs, div_value=4.0\n",
    "        )\n",
    "        self.embedding = embedding_model\n",
    "        self.wv = wv\n",
    "        self.cat = cat\n",
    "\n",
    "    def forward(self, src, src_lengths, targets=None):\n",
    "        with torch.no_grad():\n",
    "            if self.embedding is not None:\n",
    "                src_emb = torch.stack([self.embedding(\n",
    "                    torch.stack(\n",
    "                        [torch.tensor(self.wv[self.wv.index_to_key[e]]).cuda() for e in i]), self.cat).cuda() \n",
    "                        for i in src])\n",
    "            else:\n",
    "                src_emb = torch.stack([\n",
    "                    torch.stack(\n",
    "                        [torch.tensor(self.wv[self.wv.index_to_key[e]]).cuda() for e in i]).cuda() \n",
    "                        for i in src])\n",
    "\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(src_emb, src_lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # Shift targets for the next-token prediction\n",
    "        output = output[:, :-1, :].contiguous().view(-1, output.size(-1))\n",
    "        if targets is not None:\n",
    "            targets = targets[:, 1:].contiguous().view(-1)\n",
    "            loss = self.adaptive_softmax(output, targets).loss\n",
    "            return output, loss\n",
    "        else:\n",
    "            probs = self.adaptive_softmax.log_prob(output)\n",
    "            return probs.view(src.size(0), -1, probs.size(-1))\n",
    "class WordEmbeddingEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(WordEmbeddingEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x, cat = False):\n",
    "        og = x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.normalize(self.fc2(x), p=2, dim=1)  # Normalize embeddings to unit length\n",
    "        if cat:\n",
    "            x = torch.cat((og, x), axis = -1)\n",
    "        return x\n",
    "def top_k_accuracy(probs, targets, k=5):\n",
    "    # Get the top k indices along the second dimension (i.e., for each example in the batch)\n",
    "    _, top_k_indices = torch.topk(probs, k, dim=1)\n",
    "    \n",
    "    # Check if the targets are in the top k indices\n",
    "    correct = top_k_indices.eq(targets.view(-1, 1).expand_as(top_k_indices))\n",
    "    \n",
    "    # Calculate the top k accuracy\n",
    "    top_k_acc = correct.sum().float() / targets.size(0)\n",
    "    return top_k_acc.item()\n",
    "def NDCG(probs, targets, k=5):\n",
    "    # Get the top k indices\n",
    "    _, top_k_indices = torch.topk(probs, k)\n",
    "    top_k_indices = top_k_indices.cpu().numpy()\n",
    "    \n",
    "    targets = targets.cpu().numpy()\n",
    "    \n",
    "    relevance_scores = np.isin(top_k_indices, targets).astype(float)\n",
    "    DCG = relevance_scores[0] + np.sum(relevance_scores[1:] / np.log2(np.arange(2, k + 1)))\n",
    "\n",
    "    # Calculate the IDCG (Ideal DCG)\n",
    "    IDCG = 1 + np.sum(1 / np.log2(np.arange(2, relevance_scores.sum()) + 1))\n",
    "    # Calculate the NDCG\n",
    "    NDCG = DCG / IDCG\n",
    "    return NDCG\n",
    "\n",
    "def r_precision(probs, targets, R=None):\n",
    "\n",
    "    # Determine R if not provided (default to the number of relevant items for each example)\n",
    "    if R is None:\n",
    "        R = len(targets)    \n",
    "    _, top_R_indices = torch.topk(probs, k=R)\n",
    "    \n",
    "    # Check if the targets are in the top R indices\n",
    "\n",
    "    relevant_items = targets\n",
    "    num_relevant = min(R, len(relevant_items))\n",
    "    top_k_for_example = top_R_indices[:num_relevant]\n",
    "    \n",
    "    # Count how many relevant items are in the top R predictions\n",
    "    correct = torch.sum(torch.isin(top_k_for_example, relevant_items))\n",
    "\n",
    "    # Calculate R-precision\n",
    "    r_precision_score = correct / R\n",
    "    return r_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafa/.pyenv/versions/3.10.12/envs/recsys/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "# word_embedding_encoder = None\n",
    "word_embedding_encoder =  WordEmbeddingEncoder(128, 128)\n",
    "word_embedding_encoder.load_state_dict(torch.load('models/triplet_1_vec128_40.pt'))\n",
    "word_embedding_encoder.eval().cuda()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vocab_size = len(wv)  \n",
    "embedding_dim = 256\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "cutoffs = [vocab_size//1000, vocab_size // 100, vocab_size // 10, 3 * vocab_size // 4]\n",
    "train_dataset = PlaylistDataset(df_playlists_train['track_uris'], wv)\n",
    "dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn, num_workers=8)\n",
    "val_dataset = PlaylistDataset(df_playlists_val['track_uris'], wv)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn, num_workers=8)\n",
    "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers, dropout, cutoffs, wv = wv, embedding_model=word_embedding_encoder).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "writer = SummaryWriter(\"runs/lstm_lambda_1_vec128_\")\n",
    "num_epochs = 10\n",
    "max_it_per_epoch = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [05:59<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [28:08<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [06:00<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [25:52<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [04:47<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [27:58<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [05:35<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [27:29<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [05:58<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [30:07<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4995/4995 [06:02<00:00, 13.78it/s]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "print(\"Base Validation\")\n",
    "torch.manual_seed(42069)\n",
    "model.eval()\n",
    "total_val_loss = 0\n",
    "top_10_acc = 0\n",
    "top_50_acc = 0\n",
    "with torch.no_grad():\n",
    "    for src, tgt, src_attention_masks in tqdm(val_dataloader, total=len(val_dataloader)):\n",
    "        src, tgt, src_attention_masks = src.to(device), tgt.to(device), src_attention_masks.to(device)\n",
    "        src_lengths = src_attention_masks.sum(dim=1).cpu()\n",
    "        _, loss = model(src, src_lengths, targets=tgt)\n",
    "        probs = model(src, src_lengths)\n",
    "        total_val_loss += loss.item()\n",
    "        top_10_acc += top_k_accuracy(probs[:,-1], tgt[:,-1], k=10)\n",
    "        top_50_acc += top_k_accuracy(probs[:,-1], tgt[:,-1], k=50)\n",
    "        del probs\n",
    "writer.add_scalar(\"Loss/Validation\", total_val_loss / len(val_dataloader),0)\n",
    "writer.add_scalar(\"Top-10 Accuracy/Validation\", top_10_acc / len(val_dataloader),0)\n",
    "writer.add_scalar(\"Top-50 Accuracy/Validation\", top_50_acc / len(val_dataloader),0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    model.train()\n",
    "    for step, (src, tgt, src_attention_masks) in tqdm(enumerate(dataloader), total=max_it_per_epoch):\n",
    "        if step >= max_it_per_epoch:\n",
    "            break\n",
    "        src, tgt, src_attention_masks = src.to(device), tgt.to(device), src_attention_masks.to(device)\n",
    "        src_lengths = src_attention_masks.sum(dim=1).cpu()\n",
    "        size = src.shape\n",
    "        optimizer.zero_grad()\n",
    "        output, loss = model(src, src_lengths, targets=tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"Loss/Training\", loss.item(), step + epoch * max_it_per_epoch)\n",
    "\n",
    "    print(\"Validation\")\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    top_10_acc = 0\n",
    "    top_50_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt, src_attention_masks in tqdm(val_dataloader, total=len(val_dataloader)):\n",
    "            src, tgt, src_attention_masks = src.to(device), tgt.to(device), src_attention_masks.to(device)\n",
    "            src_lengths = src_attention_masks.sum(dim=1).cpu()\n",
    "            _, loss = model(src, src_lengths, targets=tgt)\n",
    "            probs = model(src, src_lengths)\n",
    "            total_val_loss += loss.item()\n",
    "            top_10_acc += top_k_accuracy(probs[:,-1], tgt[:,-1], k=10)\n",
    "            top_50_acc += top_k_accuracy(probs[:,-1], tgt[:,-1], k=50)\n",
    "            del probs\n",
    "    writer.add_scalar(\"Loss/Validation\", total_val_loss / len(val_dataloader), epoch + 1)\n",
    "    writer.add_scalar(\"Top-10 Accuracy/Validation\", top_10_acc / len(val_dataloader), epoch + 1)\n",
    "    writer.add_scalar(\"Top-50 Accuracy/Validation\", top_50_acc / len(val_dataloader), epoch + 1)\n",
    "    torch.save(model.state_dict(), f\"models/lstm_lambda_1_vec128_{epoch}.pt\") # Should be 0.5!\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_ground_truth_final\n",
       "1     2000\n",
       "5     2000\n",
       "10    2000\n",
       "25    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test_set_final.csv', sep=',')\n",
    "test_df['num_ground_truth_final'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['x'] = test_df['tracks_incomplete'].apply(lambda x: [e[\"track_uri\"].split(\":\")[-1] for e in eval(x)])\n",
    "test_df['y'] = test_df['ground_truth'].apply(lambda x: [e[\"track_uri\"].split(\":\")[-1] for e in eval(x)])\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafa/.pyenv/versions/3.10.12/envs/recsys/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "wv = KeyedVectors.load(\"word2vec128.wordvectors\", mmap='r')\n",
    "wv.sort_by_descending_frequency()\n",
    "vocab_size = len(wv)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "dropout = 0.5\n",
    "cutoffs = [vocab_size//1000, vocab_size // 100, vocab_size // 10, 3 * vocab_size // 4]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_model = None\n",
    "embedding_model = WordEmbeddingEncoder(128, 128).to(device)\n",
    "\n",
    "\n",
    "Net = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers, dropout, cutoffs, wv = wv, embedding_model=embedding_model).to(device)\n",
    "Net.load_state_dict(torch.load('models/lstm_lambda_1_vec128_4.pt'))\n",
    "\n",
    "Net.eval()\n",
    "test_dataset = TestDataset(test_df, wv)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [01:39<00:00, 80.80it/s] \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "targets = {}\n",
    "total_test_ndcg = 0\n",
    "total_test_r_precision = 0\n",
    "for src, tgt in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "    if len(tgt[0]) not in targets.keys():\n",
    "        targets[len(tgt[0])] = {\"count\": 0, \"r_precision\": 0, \"ndcg\": 0}\n",
    "    src, tgt = src.to(device), tgt.to(device)\n",
    "    src_lengths = torch.ones(src.size(0)).to(torch.long).to(device) * src.size(1)\n",
    "    probs = Net(src, src_lengths.cpu())\n",
    "    total_test_ndcg += NDCG(probs[0,-1], tgt[0,-1], k=500)\n",
    "    total_test_r_precision += r_precision(probs[0,-1], tgt)\n",
    "    targets[len(tgt[0])][\"count\"] += 1\n",
    "    targets[len(tgt[0])][\"r_precision\"] += r_precision(probs[0,-1], tgt)\n",
    "    targets[len(tgt[0])][\"ndcg\"] += NDCG(probs[0,-1], tgt, k=500)\n",
    "    del probs\n",
    "with open (\"results.txt\", \"a\") as f:\n",
    "    f.write(\"--------------------------------\\n\")\n",
    "    f.write(\"LSTM Adaptive Softmax Lambda 1\\n\")\n",
    "    f.write(\"--------------------------------\\n\")\n",
    "    f.write(f\"Test NDCG: {total_test_ndcg / len(test_dataloader)}\\n\")\n",
    "    f.write(f\"Test R-Precision: {total_test_r_precision / len(test_dataloader)}\\n\")\n",
    "    for k, v in targets.items():\n",
    "        f.write(f\"Test R-Precision for {k}: {v['r_precision'] / v['count']}\\n\")\n",
    "        f.write(f\"Test NDCG for {k}: {v['ndcg'] / v['count']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
