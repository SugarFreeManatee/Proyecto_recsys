{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egHzJ6LWXAQX"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiZopU48XAQZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import spotipy\n",
        "import spotipy.oauth2 as oauth2\n",
        "from spotipy.oauth2 import SpotifyOAuth,SpotifyClientCredentials\n",
        "import yaml\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import multiprocessing as mp\n",
        "import time\n",
        "import random\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5p8_RS8XAQa"
      },
      "outputs": [],
      "source": [
        "stream= open(\"spotify/spotify4.yaml\")\n",
        "spotify_details = yaml.safe_load(stream)\n",
        "auth_manager = SpotifyClientCredentials(client_id=spotify_details['Client_id'],\n",
        "                                        client_secret=spotify_details['client_secret'])\n",
        "sp = spotipy.client.Spotify(auth_manager=auth_manager)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCjCdUmKXAQb"
      },
      "outputs": [],
      "source": [
        "def loop_slices(path, num_slices=20):\n",
        "  cnt = 0\n",
        "  cnt1 = 0\n",
        "  mpd_playlists = []\n",
        "  unique_tracks= pd.DataFrame()\n",
        "  filenames = os.listdir(path)\n",
        "  for fname in tqdm(sorted(filenames, key=len)):\n",
        "    if fname.startswith(\"mpd.slice.\") and fname.endswith(\".json\"):\n",
        "      cnt += 1\n",
        "      fullpath = os.sep.join((path, fname))\n",
        "      f = open(fullpath)\n",
        "      js = f.read()\n",
        "      f.close()\n",
        "      current_slice = json.loads(js)\n",
        "      # Create a list of all playlists\n",
        "      for playlist in current_slice['playlists']:\n",
        "        cnt1 +=1\n",
        "        mpd_playlists.append(playlist)\n",
        "        if cnt1 == 1000:\n",
        "          cnt1=0\n",
        "          temp=pd.DataFrame(mpd_playlists)\n",
        "          temp=temp.explode('tracks')\n",
        "          temp=pd.DataFrame(temp['tracks'].apply(pd.Series))\n",
        "          unique_tracks=pd.concat([unique_tracks,temp],axis=0)\n",
        "          unique_tracks.drop_duplicates(subset=['track_uri'],inplace=True)\n",
        "          mpd_playlists = []\n",
        "      if cnt == num_slices:\n",
        "        break\n",
        "  return unique_tracks\n",
        "# Path where the json files are extracted\n",
        "path = './data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def gen_playlists(path, out):\n",
        "    cnt = 0\n",
        "    filenames = os.listdir(path)\n",
        "    \n",
        "    # Ensure the output directory exists\n",
        "    output_dir = os.path.join(out)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_file = os.path.join(output_dir, \"playlist.csv\")\n",
        "    \n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"playlist_id\\ttrack_uris\\n\")\n",
        "    \n",
        "    for fname in tqdm(sorted(filenames, key=len)):\n",
        "        if fname.startswith(\"mpd.slice.\") and fname.endswith(\".json\"):\n",
        "            cnt += 1\n",
        "            fullpath = os.path.join(path, fname)\n",
        "            \n",
        "            try:\n",
        "                with open(fullpath, 'r') as f:\n",
        "                    current_slice = json.load(f)\n",
        "                \n",
        "                # Process each playlist\n",
        "                for playlist in current_slice['playlists']:\n",
        "                    track_uris = [track['track_uri'].replace(\"spotify:track:\", '') for track in playlist['tracks']]\n",
        "                    playlist_id = playlist['pid']\n",
        "                    \n",
        "                    # Write to file\n",
        "                    with open(output_file, 'a') as f:\n",
        "                        f.write(f\"{playlist_id}\\t{track_uris}\\n\")\n",
        "            \n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON from file {fname}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    print(f\"Processed {cnt} files.\")\n",
        "\n",
        "# Path where the json files are extracted\n",
        "path = 'data/spotify_million_playlist_dataset/data'\n",
        "\n",
        "# Call the function\n",
        "playlists = gen_playlists(path, \"data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "playlist = pd.read_csv('data/playlist.csv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUQUEFbTXAQb",
        "outputId": "3864daaf-0414-458c-9c2d-2598611ccce5"
      },
      "outputs": [],
      "source": [
        "tracks = set()\n",
        "for track_uris in playlist['track_uris'].apply(eval):\n",
        "    tracks.update(track_uris)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R6Id_wnBOlL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/1m.csv')\n",
        "df_list = np.array_split(df, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb4vQo5QXAQc"
      },
      "outputs": [],
      "source": [
        "for dataframe in df_list:\n",
        "  dataframe[\"track_uri\"] = dataframe[\"track_uri\"].apply(lambda x: re.findall(r'\\w+$', x)[0])\n",
        "  dataframe[\"artist_uri\"] = dataframe[\"artist_uri\"].apply(lambda x: re.findall(r'\\w+$', x)[0])\n",
        "  dataframe[\"album_uri\"] = dataframe[\"album_uri\"].apply(lambda x: re.findall(r'\\w+$', x)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlTResYZXAQd"
      },
      "outputs": [],
      "source": [
        "cols = ['track_uri', 'artist_uri', 'album_uri']\n",
        "new_df_list = []\n",
        "for dataframe in df_list:\n",
        "  new_dataframe = dataframe[cols]\n",
        "  new_df_list.append(new_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9Aqes_OXAQd"
      },
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_K0a1wvXAQd"
      },
      "source": [
        "Using the Spotify API for Feature Extraction and Saving Results to a CSV File and Errors to a Log File\n",
        "\n",
        "I was using SP.track first, but I realised that it would take a lot of time and I would have to counter a lot of Api rate limits,Â so I used SP.tracks and SP.artists instead. They accept lists with a 50-URI maximum and handle them in a single request, so it took a lot less time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvlQph_fXAQd",
        "outputId": "2881bded-56c0-42fd-f32d-569a6b185523"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for dataframe in tqdm(new_df_list[0:], total=len(new_df_list[0:])):\n",
        "  print(count)\n",
        "  t_uri=dataframe[\"track_uri\"].unique()\n",
        "  a_uri=dataframe[\"artist_uri\"].unique()\n",
        "  f = open('final_data/audio_features_sample_'+str(count)+'.csv','a')\n",
        "  e=0\n",
        "  for i in range(0,len(t_uri),100):\n",
        "      try:\n",
        "       track_feature = sp.audio_features(t_uri[i:i+100])\n",
        "       track_df = pd.DataFrame(track_feature)\n",
        "       csv_data = track_df.to_csv(header=True,index=False)\n",
        "       f.write(csv_data)\n",
        "      except Exception as error:\n",
        "          e+=1\n",
        "          r = open(\"audio_features_log_\"+str(count)+\".txt\", \"a\")\n",
        "          r.write(datetime.datetime.now().strftime(\"%d.%b %Y %H:%M:%S\")+\": \"+str(error)+'\\n')\n",
        "          r.close()\n",
        "          time.sleep(1)\n",
        "          continue\n",
        "  count+=1\n",
        "  r = open(\"audio_features_log_\"+str(count)+\".txt\", \"a\")\n",
        "  r.write(datetime.datetime.now().strftime(\"%d.%b %Y %H:%M:%S\")+\" _________________________ \"+\"Total Number Of Errors : \"+str(e)+\" _________________________ \"+'\\n')\n",
        "  r.close()\n",
        "  f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e246d2215c418239c9316a1ebf2d8abb44dc50b2e5b0e29defd87143398aa387"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
