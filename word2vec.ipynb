{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from gensim.models import Word2Vec, KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playlists as sentences, ids as words\n",
    "\n",
    "df_playlists = pd.read_csv('data/playlist.tsv', sep='\\t')\n",
    "\n",
    "playlists = df_playlists.track_uris.apply(eval).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=playlists, vector_size=128, window=100, min_count=1, workers=8)\n",
    "model.save(\"word2vec128.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec128.model\")\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec128.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load(\"word2vec128.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([-1.7170135e+00, -2.3962460e+00,  6.5327615e-01,  1.4792818e+00,\n",
       "        -4.1627612e+00, -3.7363815e+00, -4.0420847e+00,  5.5401316e+00,\n",
       "         3.6785965e+00, -8.0635004e+00, -2.8311641e+00, -3.8945107e+00,\n",
       "        -3.0691066e-01,  6.4100319e-01, -8.6864406e-01, -3.9300735e+00,\n",
       "         5.5363994e+00, -2.9236808e+00,  5.6453266e+00,  2.1363355e-03,\n",
       "        -3.5578997e+00,  3.2450306e+00,  1.3382255e+00, -3.0441615e-01,\n",
       "         2.0134881e+00, -4.1783738e+00,  7.8383976e-01, -8.2223302e-01,\n",
       "         1.3025694e+00,  7.4136597e-01,  7.2722640e+00,  3.9815881e+00,\n",
       "         2.9444141e+00,  5.9522386e+00,  2.3802121e+00, -2.0279431e+00,\n",
       "         4.1253424e+00, -1.7454195e-01, -9.4524580e-01, -3.1904263e+00,\n",
       "        -4.7110631e-03,  8.5059285e-01, -6.3117027e-01,  3.9513373e+00,\n",
       "         1.6436853e+00,  3.4933012e+00,  1.4838673e+00, -2.1465943e+00,\n",
       "        -1.5491265e+00, -4.3947349e+00,  7.1400744e-01, -5.3090148e+00,\n",
       "         1.5631786e-01,  6.2345719e+00, -3.4194691e+00,  2.1370013e+00,\n",
       "         4.5780854e+00,  1.3825786e+00,  2.5773647e+00,  2.8322127e+00,\n",
       "         3.8613379e+00,  3.7926257e+00,  2.1326935e+00,  1.1958861e+00,\n",
       "         4.0365687e-01, -8.2627767e-01, -3.0224686e+00,  8.8868344e-01,\n",
       "        -1.2785240e-01,  1.2050645e+00, -5.3792443e+00, -1.4539599e+00,\n",
       "         4.3659248e+00,  5.4981351e+00,  1.5162416e+00, -1.4722443e+00,\n",
       "        -4.1534677e+00,  1.7998865e+00,  3.7725706e+00,  3.8587205e+00,\n",
       "        -5.3895032e-01, -2.7846634e+00,  1.7337765e+00, -1.9791461e+00,\n",
       "        -4.4604951e-01, -7.9278952e-01, -3.0289760e+00,  1.5014273e+00,\n",
       "        -4.9212542e-01, -1.0468755e+00, -5.9149055e+00,  2.6948993e+00,\n",
       "        -3.1355045e+00,  3.3383954e+00, -1.3963495e+00,  3.5011542e+00,\n",
       "        -3.0958381e-01,  1.5166982e+00, -4.0749202e+00,  2.4101639e+00,\n",
       "         5.1711645e+00, -2.3846655e+00,  3.3324319e-01,  4.8198066e+00,\n",
       "         1.1985487e+00, -3.6971428e+00, -3.2625034e+00, -2.0324770e-01,\n",
       "        -3.5367169e+00,  6.0233922e+00, -2.9396648e+00, -1.8011481e+00,\n",
       "         3.8317853e-01, -1.6188488e+00, -4.9074426e+00, -2.5548527e+00,\n",
       "         3.2388544e-01,  1.0742848e+00, -3.9425826e+00, -4.9350786e+00,\n",
       "        -2.7492483e+00, -8.3967662e-01, -3.0705411e+00,  1.2902908e+00,\n",
       "        -4.8682046e+00, -1.7721691e+00,  1.5819183e-02, -3.2309082e+00],\n",
       "       dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['0UaMYEvWZi0ZqiDOoHU3YI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mappeamos los tracks a vectores usando W2V, siguiendo [el siguiente paper](https://arxiv.org/pdf/2304.12257). Ahora debemos hacer el entrenamiento contrastivo sobre estos vectores, tomando en cuenta su coocurrencia en playlists (como menciona el paper), pero ademas la similitud de sus features de audio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
